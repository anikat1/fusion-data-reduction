{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5956f2-f071-45bb-8b1d-ab3774b43b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random \n",
    "import tqdm\n",
    "\n",
    "import adios2 as ad2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep adios2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af5791-9cd6-42b4-b36b-4b261bba7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install adios2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4193fcd-2926-48e0-93f1-0fc7ee95bb73",
   "metadata": {},
   "source": [
    "#Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d6316-e63b-4a1b-af00-1e2f39d3530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_f0(istep, expdir=None, iphi=None, inode=0, nnodes=None, average=False, \n",
    "            randomread=0.0, nchunk=16, fieldline=False):\n",
    "    \"\"\"\n",
    "    Read XGC f0 data\n",
    "    \"\"\"\n",
    "    def adios2_get_shape(f, varname):\n",
    "        nstep = int(f.available_variables()[varname]['AvailableStepsCount'])\n",
    "        shape = f.available_variables()[varname]['Shape']\n",
    "        lshape = None\n",
    "        if shape == '':\n",
    "            ## Accessing Adios1 file\n",
    "            ## Read data and figure out\n",
    "            v = f.read(varname)\n",
    "            lshape = v.shape\n",
    "        else:\n",
    "            lshape = tuple([ int(x.strip(',')) for x in shape.strip().split() ])\n",
    "        return (nstep, lshape)\n",
    "\n",
    "    fname = os.path.join(expdir, 'restart_dir/xgc.f0.%05d.bp'%istep)\n",
    "    if randomread > 0.0:\n",
    "        ## prefetch to get metadata\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0]\n",
    "            _nnodes = nsize[2] if nnodes is None else nnodes\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "        assert _nnodes%nchunk == 0\n",
    "        _lnodes = list(range(inode, inode+_nnodes, nchunk))\n",
    "        lnodes = random.sample(_lnodes, k=int(len(_lnodes)*randomread))\n",
    "        lnodes = np.sort(lnodes)\n",
    "\n",
    "        lf = list()\n",
    "        li = list()\n",
    "        for i in tqdm(lnodes):\n",
    "            li.append(np.array(range(i,i+nchunk), dtype=np.int32))\n",
    "            with ad2.open(fname, 'r') as f:\n",
    "                nphi = nsize[0] if iphi is None else 1\n",
    "                iphi = 0 if iphi is None else iphi\n",
    "                start = (iphi,0,i,0)\n",
    "                count = (nphi,nmu,nchunk,nvp)\n",
    "                _f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "                lf.append(_f)\n",
    "        i_f = np.concatenate(lf, axis=2)\n",
    "        lb = np.concatenate(li)\n",
    "    elif fieldline is True:\n",
    "        import networkx as nx\n",
    "\n",
    "        fname2 = os.path.join(expdir, 'xgc.mesh.bp')\n",
    "        with ad2.open(fname2, 'r') as f:\n",
    "            _nnodes = int(f.read('n_n', ))\n",
    "            nextnode = f.read('nextnode')\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        for i in range(_nnodes):\n",
    "            G.add_node(i)\n",
    "        for i in range(_nnodes):\n",
    "            G.add_edge(i, nextnode[i])\n",
    "            G.add_edge(nextnode[i], i)\n",
    "        cc = [x for x in list(nx.connected_components(G)) if len(x) >= 16]\n",
    "\n",
    "        li = list()\n",
    "        for k, components in enumerate(cc):\n",
    "            DG = nx.DiGraph()\n",
    "            for i in components:\n",
    "                DG.add_node(i)\n",
    "            for i in components:\n",
    "                DG.add_edge(i, nextnode[i])\n",
    "            \n",
    "            cycle = list(nx.find_cycle(DG))\n",
    "            DG.remove_edge(*cycle[-1])\n",
    "            \n",
    "            path = nx.dag_longest_path(DG)\n",
    "            #print (k, len(components), path[0])\n",
    "            for i in path[:len(path)-len(path)%16]:\n",
    "                li.append(i)\n",
    "\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0] if iphi is None else 1\n",
    "            iphi = 0 if iphi is None else iphi\n",
    "            _nnodes = nsize[2]\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "            start = (iphi,0,0,0)\n",
    "            count = (nphi,nmu,_nnodes,nvp)\n",
    "            logging.info (f\"Reading: {start} {count}\")\n",
    "            i_f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "        \n",
    "        _nnodes = len(li)-inode if nnodes is None else nnodes\n",
    "        lb = np.array(li[inode:inode+_nnodes], dtype=np.int32)\n",
    "        logging.info (f\"Fieldline: {len(lb)}\")\n",
    "        logging.info (f\"{lb}\")\n",
    "        i_f = i_f[:,:,lb,:]\n",
    "    else:\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0] if iphi is None else 1\n",
    "            iphi = 0 if iphi is None else iphi\n",
    "            _nnodes = nsize[2]-inode if nnodes is None else nnodes\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "            start = (iphi,0,inode,0)\n",
    "            count = (nphi,nmu,_nnodes,nvp)\n",
    "            logging.info (f\"Reading: {start} {count}\")\n",
    "            i_f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "            #e_f = f.read('e_f')\n",
    "        li = list(range(inode, inode+_nnodes))\n",
    "        lb = np.array(li, dtype=np.int32)\n",
    "\n",
    "    # if i_f.shape[3] == 31:\n",
    "    #     i_f = np.append(i_f, i_f[...,30:31], axis=3)\n",
    "    #     # e_f = np.append(e_f, e_f[...,30:31], axis=3)\n",
    "    if i_f.shape[3] == 39:\n",
    "        i_f = np.append(i_f, i_f[...,38:39], axis=3)\n",
    "        i_f = np.append(i_f, i_f[:,38:39,:,:], axis=1)\n",
    "\n",
    "    Z0 = np.moveaxis(i_f, 1, 2)\n",
    "\n",
    "    if average:\n",
    "        Z0 = np.mean(Z0, axis=0)\n",
    "        zlb = lb\n",
    "    else:\n",
    "        Z0 = Z0.reshape((-1,Z0.shape[2],Z0.shape[3]))\n",
    "        _lb = list()\n",
    "        for i in range(nphi):\n",
    "            _lb.append( i*100_000_000 + lb)\n",
    "        zlb = np.concatenate(_lb)\n",
    "    \n",
    "    #zlb = np.concatenate(li)\n",
    "    zmu = np.mean(Z0, axis=(1,2))\n",
    "    zsig = np.std(Z0, axis=(1,2))\n",
    "    zmin = np.min(Z0, axis=(1,2))\n",
    "    zmax = np.max(Z0, axis=(1,2))\n",
    "    Zif = (Z0 - zmin[:,np.newaxis,np.newaxis])/(zmax-zmin)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    return (Z0, Zif, zmu, zsig, zmin, zmax, zlb)\n",
    "\n",
    "def read_data(base_data_dir, super_data_dir, num_channels=1):\n",
    "    Z0, Zif, zmu, zsig, zmin, zmax, zlb = read_f0(420, expdir=base_data_dir, iphi=0)\n",
    "    Z0_s, Zif_s, zmu_s, zsig_s, zmin_s, zmax_s, zlb_s = read_f0(420, expdir=super_data_dir, iphi=0)\n",
    "    print('base:',Zif.shape, zlb.shape, zmu.shape, zsig.shape)\n",
    "    print('super:',Zif_s.shape, zlb_s.shape, zmu_s.shape, zsig_s.shape)\n",
    "    \n",
    "    lx = list()\n",
    "    ly = list()\n",
    "    for i in range(0,len(Zif)-num_channels,num_channels):\n",
    "        X = Zif[i:i+num_channels,:,:]\n",
    "        lx.append(X)\n",
    "        ly.append(zlb[i:i+num_channels])\n",
    "    \n",
    "    X_train, X_test, id_train, id_test = train_test_split(lx, ly, test_size=0.10, random_state=42)\n",
    "    \n",
    "    Y_train = list()\n",
    "    Y_test = list()\n",
    "    \n",
    "    for ids in id_train:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        Y_train.append(X)\n",
    "    \n",
    "    for ids in id_test:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        Y_test.append(X)\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, id_train, id_test\n",
    "\n",
    "\n",
    "class XGCSuperDataset:\n",
    "    def __init__(self, base_X, base_Y, ids, transform=None, patch_size=5):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.image_list = base_X\n",
    "        self.label_list = base_Y\n",
    "        self.id_list = ids\n",
    "        self.transform = transform\n",
    "        \n",
    "        orig_sz = base_X[0].shape[1]\n",
    "        self.image_size = int(orig_sz/patch_size)\n",
    "        \n",
    "        self.num_patches = int((orig_sz*orig_sz)/(patch_size*patch_size))\n",
    "        self.ids =[]\n",
    "        self.sub_ids=[]\n",
    "        \n",
    "        for i in range(0,len(self.image_list)):\n",
    "            self.ids+=self.num_patches*[i]\n",
    "            self.sub_ids+=range(0,self.num_patches)\n",
    "        \n",
    "        print('data init:',self.num_patches,len(self.image_list),len(self.label_list),\n",
    "              len(self.ids),len(self.sub_ids))\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        base_image = self.image_list[self.ids[i]]\n",
    "        base_image=base_image[0,:,:]\n",
    "        \n",
    "        super_image = self.label_list[self.ids[i]]\n",
    "        super_image=super_image[0,:,:]\n",
    "        #print(orig_image.shape)\n",
    "        \n",
    "        sub_idx = self.sub_ids[i]\n",
    "        \n",
    "        ridx = int(sub_idx/self.image_size)\n",
    "        cidx = int(sub_idx%self.image_size)\n",
    "        \n",
    "        rs= ridx*self.patch_size\n",
    "        re = rs+self.patch_size\n",
    "        cs = cidx*self.patch_size\n",
    "        ce = cs+self.patch_size\n",
    "        \n",
    "        image = base_image[rs:re,cs:ce]\n",
    "        image = image[np.newaxis,:,:]\n",
    "        \n",
    "        label = super_image[rs:re,cs:ce]\n",
    "        label = label[np.newaxis,:,:]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        sample = {'X': torch.as_tensor(image.copy()).float(), \n",
    "                  'Y': torch.as_tensor(label.copy()).float(),\n",
    "                  'label': self.id_list[self.ids[i]],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96897bba-3174-449d-9aa0-ac081a4d233d",
   "metadata": {},
   "source": [
    "Hyper Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90926f1-eaf4-4839-8725-34bd18bf245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, f_size = 3, z_dim = 64, out_size=16, in_size=16,s_dim=100):\n",
    "        super(HyperNetwork, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.f_size = f_size\n",
    "        self.out_size = out_size\n",
    "        self.in_size = in_size\n",
    "        \n",
    "        #64 X 16*3*3\n",
    "        self.w1 = Parameter(torch.fmod(torch.randn((self.z_dim, self.out_size*self.f_size*self.f_size)).cuda(),2))\n",
    "        #16*3*3\n",
    "        self.b1 = Parameter(torch.fmod(torch.randn((self.out_size*self.f_size*self.f_size)).cuda(),2))\n",
    "        \n",
    "        #64 X 16*64\n",
    "        self.w2 = Parameter(torch.fmod(torch.randn((self.z_dim, self.in_size*self.z_dim)).cuda(),2))\n",
    "        #16*64 X 1\n",
    "        self.b2 = Parameter(torch.fmod(torch.randn((self.in_size*self.z_dim)).cuda(),2))\n",
    "        \n",
    "        #100 X 16*64\n",
    "        self.w3 = Parameter(torch.fmod(torch.randn((self.s_dim, self.in_size*self.z_dim)).cuda(),2))\n",
    "        #16*64 X 1\n",
    "        self.b3 = Parameter(torch.fmod(torch.randn((self.in_size*self.z_dim)).cuda(),2))\n",
    "        \n",
    "    def forward(self, z,si): #100 \n",
    "\n",
    "        h_in = torch.matmul(z, self.w2) + self.b2    # input 64 dim , output = 16*64\n",
    "        h_in = h_in.view(self.in_size, self.z_dim)   #16 X 64\n",
    "        \n",
    "        h_spatial_in = torch.matmul(si,self.w3) + self.b3  #input 100 dim, output = 16*64 \n",
    "        h_spatial_in = h_spatial_in.view(self.in_size, self.z_dim) #16 X 64\n",
    "        \n",
    "        h_new = h_spatial_in + h_in #Add values of learnable and spatial embeddings once in same latent space\n",
    "\n",
    "#         h_final = torch.matmul(h_in, self.w1) + self.b1  # input 16 X 64, output = 16 X 16*3*3 \n",
    "#         kernel = h_final.view(self.out_size, self.in_size, self.f_size, self.f_size) # 16 X 16 X 3 X 3\n",
    "        \n",
    "        h_final = torch.matmul(h_new, self.w1) + self.b1  # input 16 X 64, output = 16 X 16*3*3 \n",
    "        kernel = h_final.view(self.out_size, self.in_size, self.f_size, self.f_size) # 16 X 16 X 3 X 3\n",
    "\n",
    "        return kernel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2c45f-0bab-42b3-8009-a6b9c66bf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet Block\n",
    "\n",
    "class IdentityLayer(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size=16, out_size=16, downsample = False):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.in_size = in_size\n",
    "        if downsample:\n",
    "            self.stride1 = 2\n",
    "            self.reslayer = nn.Conv2d(in_channels=self.in_size, out_channels=self.out_size, \n",
    "                                      stride=2, kernel_size=1)\n",
    "        else:\n",
    "            self.stride1 = 1\n",
    "            self.reslayer = IdentityLayer()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_size)\n",
    "        self.bn2 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "    def forward(self, x, conv1_w, conv2_w):\n",
    "\n",
    "        residual = self.reslayer(x)\n",
    "\n",
    "        out = F.relu(self.bn1(F.conv2d(x, conv1_w, stride=self.stride1, padding=1)), inplace=True)\n",
    "        out = self.bn2(F.conv2d(out, conv2_w, padding=1))\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50809a-9946-493a-a5e5-e496578a6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, z_num, z_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        self.z_list = nn.ParameterList()\n",
    "        self.z_num = z_num\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        h,k = self.z_num\n",
    "\n",
    "        for i in range(h):\n",
    "            for j in range(k):\n",
    "                self.z_list.append(Parameter(torch.fmod(torch.randn(self.z_dim).cuda(), 2)))\n",
    "\n",
    "    def forward(self, hyper_net,si): #si is the spatial encoding vector.\n",
    "        ww = []\n",
    "        h, k = self.z_num\n",
    "        for i in range(h):\n",
    "            w = []\n",
    "            for j in range(k):\n",
    "                w.append(hyper_net(self.z_list[i*k + j],si))\n",
    "            ww.append(torch.cat(w, dim=1))\n",
    "        return torch.cat(ww, dim=0)\n",
    "\n",
    "\n",
    "class PrimaryNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=64, patch_size=5):\n",
    "        super(PrimaryNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.patch_size= patch_size\n",
    "        self.z_dim = z_dim\n",
    "        self.hope = HyperNetwork(z_dim=self.z_dim)\n",
    "\n",
    "        self.zs_size = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1],\n",
    "                        [2, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2],\n",
    "                        [4, 2], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4]]\n",
    "\n",
    "        self.filter_size = [[16,16], [16,16], [16,16], [16,16], [16,16], [16,16], [16,32], [32,32], [32,32], [32,32],\n",
    "                            [32,32], [32,32], [32,64], [64,64], [64,64], [64,64], [64,64], [64,64]]\n",
    "\n",
    "        self.res_net = nn.ModuleList()\n",
    "\n",
    "        for i in range(18):\n",
    "            down_sample = False\n",
    "            if i > 5 and i % 6 == 0:\n",
    "                down_sample = True\n",
    "            self.res_net.append(ResNetBlock(self.filter_size[i][0], self.filter_size[i][1], downsample=down_sample))\n",
    "\n",
    "        self.zs = nn.ModuleList()\n",
    "\n",
    "        for i in range(36):\n",
    "            self.zs.append(Embedding(self.zs_size[i], self.z_dim))\n",
    "\n",
    "        self.global_avg = nn.AvgPool2d(8)\n",
    "        self.final = nn.Linear(256,self.patch_size*self.patch_size)\n",
    "\n",
    "    def forward(self, x,si): # where si is the (num_nodes X 1) spatial-encoding vector\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #print('conv1:',x.shape)\n",
    "        for i in range(18):\n",
    "            # if i != 15 and i != 17:\n",
    "            w1 = self.zs[2*i](self.hope,si) #Note the SAME si is passed for all sub_parts x of a single image X_i\n",
    "            w2 = self.zs[2*i+1](self.hope,si)\n",
    "            x = self.res_net[i](x, w1, w2)\n",
    "            #print('resnet:',i,x.shape)\n",
    "        \n",
    "        #print('final resnet:',x.shape)\n",
    "        \n",
    "        #x = self.global_avg(x)\n",
    "        #print('avg pool:',x.shape)\n",
    "        x = self.final(x.view(-1,256))\n",
    "        x = x.view(-1,1,self.patch_size,self.patch_size)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bbfd5-2eb2-4bf6-a4cf-c1ed50943990",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494f0a2-444d-4335-aeda-fbaaaab35825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfc3ed-9aac-49e9-82e6-f6df6e1bb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(patch_size, batch_size):\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test, id_train, id_test = read_data(dir_base_data, dir_super_data)\n",
    "    \n",
    "    #print(len(X_train), len(X_test), len(Y_train), len(Y_test))\n",
    "   \n",
    "    trainset = XGCSuperDataset(X_train, Y_train, id_train, transform=None, patch_size=patch_size)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "    \n",
    "    testset = XGCSuperDataset(X_test, Y_test, id_test, transform=None, patch_size=patch_size)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe9d20-48be-43d8-a3b3-f68c24256203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(device, net, testloader, criterion, batch_size):\n",
    "    correct = 0.\n",
    "    total = len(testloader)*batch_size\n",
    "    \n",
    "    for tdata in testloader:\n",
    "        timages, tlabels = tdata['X'], tdata['Y']\n",
    "        tlables = Variable(tlabels.cuda())\n",
    "        toutputs = net(Variable(timages.cuda()))\n",
    "        predicted = toutputs.cpu().data\n",
    "        correct+= criterion(predicted,tlabels)\n",
    "        \n",
    "    return correct.item(), total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b2d1-94c3-40a1-b6b7-4716cf5851ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "save_freq = 20\n",
    "patch_size = 8 \n",
    "print_freq = 20\n",
    "dir_out = 'checkpoint/'\n",
    "dir_resume = 'checkpoint/hypernetworks_plasma.pth/'\n",
    "dir_base_data = 'gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2' \n",
    "dir_super_data = 'gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2_4x' \n",
    "resume = False\n",
    "\n",
    "\n",
    "if not os.path.exists(dir_out):\n",
    "        os.makedirs(dir_out)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224b65f",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe02bb5-364b-4fcc-b076-53cad941eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device):\n",
    "    trainloader, testloader = set_data(patch_size, batch_size)\n",
    "    \n",
    "    net = PrimaryNetwork(patch_size=patch_size)\n",
    "    best_accuracy = 10000.\n",
    "\n",
    "    if resume:\n",
    "        ckpt = torch.load(args.dir_resume)\n",
    "        net.load_state_dict(ckpt['net'])\n",
    "        best_accuracy = ckpt['acc']\n",
    "\n",
    "    net.cuda()\n",
    "\n",
    "    learning_rate = 0.002\n",
    "    weight_decay = 0.0005\n",
    "    milestones = [168000, 336000, 400000, 450000, 550000, 600000]\n",
    "    max_iter = epochs\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    total_iter = 0\n",
    "    epoch = 0\n",
    "    #print_freq = args.print_freq\n",
    "    num_batches=len(trainloader)\n",
    "    loss_file=open(dir_out+'loss.txt','w')\n",
    "    loss_file.write('epoch,loss,val_loss\\n')\n",
    "    start = time.time()\n",
    "    \n",
    "    print('data loader:',len(trainloader),len(testloader))\n",
    "    while total_iter < max_iter:\n",
    "\n",
    "        running_loss = 0.0\n",
    "        epoch_loss=0\n",
    "        epoch=0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            inputs, labels = data['X'], data['Y'], data['S']\n",
    "            nid, rid, cid = data['label'],data['rsid'], data['csid']\n",
    "            \n",
    "            \n",
    "            inputs= Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            #print('train:',inputs.shape, labels.shape, outputs.shape)\n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels) #+ physics_loss()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss+=loss.item()\n",
    "            if i % print_freq == (print_freq-1):\n",
    "                print(\"[Epoch %d, Total Iterations %4d] Loss: %.4f\" % (epoch + 1, \n",
    "                                                                       total_iter + 1, \n",
    "                                                                       running_loss/print_freq))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            epoch += 1\n",
    "        \n",
    "        total_iter += 1\n",
    "\n",
    "        correct, total= validate(device, net, testloader, criterion, batch_size)\n",
    "        epoch_loss/=num_batches\n",
    "        val_loss = correct/total\n",
    "        string1=str(total_iter)+','+str(epoch_loss)+','+str(val_loss)+'\\n'\n",
    "        loss_file.write(string1)\n",
    "        accuracy = (100. * correct) / total\n",
    "        print('After epoch %d, accuracy: %.4f %%' % (total_iter, accuracy))\n",
    "\n",
    "        if accuracy < best_accuracy:\n",
    "            print('Saving model...')\n",
    "            state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': accuracy\n",
    "            }\n",
    "            torch.save(state, dir_out+'hypernet_plasma_super_resolve_'+str(total_iter)+'.pth')\n",
    "            best_accuracy = accuracy\n",
    "        \n",
    "    print('Finished Training')\n",
    "    state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': accuracy\n",
    "            }\n",
    "    torch.save(state, dir_out+'last.pth')\n",
    "    loss_file.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c8315-8308-4061-ba04-8975ec03de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(device)\n",
    "\n",
    "print('Finished Training!!')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8983e3f-cb12-4ff9-82f8-ce05ace6dce7",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31956e-a86e-427e-8bb8-d7f0ea6c9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, dir_base_data, dir_super_data, patch_size):\n",
    "    X_train, X_test, Y_train, Y_test, id_train, id_test = read_data(dir_base_data, dir_super_data)\n",
    "    \n",
    "    testset = XGCSuperDataset(X_test, Y_test, id_test, transform=None, patch_size=patch_size)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "    \n",
    "    return testloader, X_test, Y_test, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300562b-baf2-4d53-a2ce-d50c0f537a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device, dir_model):\n",
    "    net = PrimaryNetwork(patch_size=patch_size)\n",
    "    ckpt = torch.load(dir_model, map_location=device)\n",
    "    state_dict = ckpt['net']\n",
    "    \n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for k, v in state_dict.items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "        state_dict = new_state_dict\n",
    "    \n",
    "    net.to(device=device)\n",
    "    net.load_state_dict(state_dict)\n",
    "    \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3701061-165b-4da7-9b29-8573e6f7fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(map_pred_img,predictions, rid, cid, labels, patch_size):\n",
    "    \n",
    "    for l in range(0,len(labels)):\n",
    "        map_pred_img[labels[l][0]][rid[l]:rid[l]+patch_size,cid[l]:cid[l]+patch_size] = predictions[l,:,:]\n",
    "        \n",
    "    return map_pred_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78504566-78ca-4dba-a4f2-33e379807561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d702c-9a34-4155-98f4-3d9f7795ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device, batch_size, patch_size, dir_out, dir_model, dir_base_data, dir_super_data):\n",
    "    model = load_model(device, dir_model)\n",
    "    \n",
    "    testloader, Xtest, Ytest, id_test = load_data(batch_size, dir_base_data, dir_super_data, patch_size)\n",
    "    model.eval()\n",
    "    map_pred_img_ensemble={}\n",
    "    \n",
    "    for tid in id_test:\n",
    "        #print('test labels:',tid[0])\n",
    "        map_pred_img_ensemble[tid[0]]= np.zeros((40,40))\n",
    "    \n",
    "    print('testloader:',len(testloader))\n",
    "    \n",
    "    for i, data in enumerate(testloader,0):\n",
    "        timages, tlabels = data['X'], data['Y']\n",
    "        nid, rid, cid = data['label'],data['rsid'], data['csid']\n",
    "        #timages = timages.to(device=device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            toutputs = model(Variable(timages.cuda()))\n",
    "            predicted = toutputs.cpu().data\n",
    "        \n",
    "        predicted = predicted.squeeze()\n",
    "        predicted = predicted.numpy()\n",
    "        tids = list(nid.numpy())\n",
    "        rid = list(rid.numpy())\n",
    "        cid = list(cid.numpy())\n",
    "        #orig_image = tlabels.numpy()\n",
    "        #print(i,predicted.shape,orig_image.shape,len(rid),len(cid),len(tlabels))\n",
    "        \n",
    "        map_pred_img_ensemble = aggregate(map_pred_img_ensemble,predicted, rid, cid, \n",
    "                                          tids, patch_size)\n",
    "    \n",
    "    fname = 'rmse_xgc_test_'+str(batch_size)+'_'+str(len(testloader))+'.txt'\n",
    "    error_file=open(dir_out+fname,'w')\n",
    "    total_err =0\n",
    "    Ypred =[]\n",
    "    for l in range(0,len(id_test)):\n",
    "        tid = id_test[l][0]\n",
    "        targets = map_pred_img_ensemble[tid]\n",
    "        #loss = np.mean((Xtest[l] - targets)**2)\n",
    "        loss = rmse(targets, Ytest[l][0])\n",
    "        total_err+=loss\n",
    "        #print(tid,loss,Xtest[l][0].shape, targets.shape)\n",
    "        string=str(tid)+','+str(loss.item())+'\\n'\n",
    "        error_file.write(string)\n",
    "        Ypred.append(targets)\n",
    "        \n",
    "    print('total:',total_err/(len(testloader)*batch_size))\n",
    "    string='total,'+str(total_err)+'\\n'\n",
    "    error_file.write(string)\n",
    "        \n",
    "    error_file.close()\n",
    "    \n",
    "    return Xtest, Ytest, Ypred, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507f23b-9499-4e12-ae43-7d97fd8cd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "patch_size = 8\n",
    "dir_out = 'results/super-resolve/'\n",
    "dir_model = 'checkpoint/hypernet_plasma_super_resolve_87.pth'\n",
    "dir_base_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2'\n",
    "dir_super_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2_4x'\n",
    "if not os.path.exists(dir_out):\n",
    "        os.makedirs(dir_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85ed70-aaf4-469b-9ee5-e264456f7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xtest, ytest, ypred, idtest = test(device,batch_size, patch_size, dir_out, dir_model,\n",
    "                                   dir_base_data, dir_super_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51905033-4884-43e8-9e0f-a1eeb98f006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,len(idtest)):\n",
    "    np.save(dir_out+'f_pred_'+str(idtest[l][0]),ypred[l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d2f5e-0f4e-411c-be9b-5f8a5951aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ny, nx = ytest[0].shape\n",
    "ix = np.linspace(0, nx-1, nx)\n",
    "iy = np.linspace(0, ny-1, ny)\n",
    "Mx, My = np.meshgrid(ix, iy)\n",
    "\n",
    "for l in range(0,len(ytest)):\n",
    "    #plt.figure(figsize=(4, 9))\n",
    "    print('idx:',l)\n",
    "    f = plt.figure(figsize=(12, 8))\n",
    "    f.add_subplot(1,3, 1)\n",
    "    plt.imshow(xtest[l][0], origin='lower')\n",
    "    #plt.colorbar()\n",
    "    plt.contour(Mx, My, ytest[l][0], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('input %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    f.add_subplot(1,3, 2)\n",
    "    plt.imshow(ytest[l][0], origin='lower')\n",
    "    #plt.colorbar()\n",
    "    plt.contour(Mx, My, ytest[l][0], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('original %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    f.add_subplot(1,3, 3)\n",
    "    plt.imshow(ypred[l], origin='lower')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.contour(Mx, My, ypred[l], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    RMSE = rmse(ypred[l], ytest[l][0])\n",
    "    plt.text(.02,.95,'RMSE: {:.04f}'.format(RMSE), fontsize=14, c='white')\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('predicted %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840477ed",
   "metadata": {},
   "source": [
    "# Plot Error across Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all(base_data_dir, super_data_dir, num_channels=1):\n",
    "    Z0, Zif, zmu, zsig, zmin, zmax, zlb = read_f0(420, expdir=base_data_dir, iphi=0)\n",
    "    Z0_s, Zif_s, zmu_s, zsig_s, zmin_s, zmax_s, zlb_s = read_f0(420, expdir=super_data_dir, iphi=0)\n",
    "    print('base:',Zif.shape, zlb.shape, zmu.shape, zsig.shape)\n",
    "    print('super:',Zif_s.shape, zlb_s.shape, zmu_s.shape, zsig_s.shape)\n",
    "    \n",
    "    lx = list()\n",
    "    ly = list()\n",
    "    lid = list()\n",
    "    for i in range(0,len(Zif)-num_channels,num_channels):\n",
    "        X = Zif[i:i+num_channels,:,:]\n",
    "        lx.append(X)\n",
    "        lid.append(zlb[i:i+num_channels])\n",
    "    \n",
    "    print('lid:',lid[:10])\n",
    "    for ids in lid:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        ly.append(X)\n",
    "    \n",
    "    \n",
    "    return lx, ly, lid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16935ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(batch_size, dir_base_data, dir_super_data, patch_size):\n",
    "    X_test, Y_test, id_test = read_all(dir_base_data, dir_super_data)\n",
    "    \n",
    "    testset = XGCSuperDataset(X_test, Y_test, id_test, transform=None, patch_size=patch_size)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "    return testloader, X_test, Y_test, id_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(device, batch_size, patch_size, dir_out, dir_model, dir_base_data, dir_super_data):\n",
    "    model = load_model(device, dir_model)\n",
    "    \n",
    "    testloader, Xtest, Ytest, id_test = load_all(batch_size, dir_base_data, dir_super_data, patch_size)\n",
    "    model.eval()\n",
    "    map_pred_img_ensemble={}\n",
    "    \n",
    "    for tid in id_test:\n",
    "        #print('test labels:',tid[0])\n",
    "        map_pred_img_ensemble[tid[0]]= np.zeros((40,40))\n",
    "    \n",
    "    print('testloader:',len(testloader))\n",
    "    \n",
    "    for i, data in enumerate(testloader,0):\n",
    "        timages, tlabels = data['X'], data['Y']\n",
    "        nid, rid, cid = data['label'],data['rsid'], data['csid']\n",
    "        #timages = timages.to(device=device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            toutputs = model(Variable(timages.cuda()))\n",
    "            predicted = toutputs.cpu().data\n",
    "        \n",
    "        predicted = predicted.squeeze()\n",
    "        predicted = predicted.numpy()\n",
    "        tids = list(nid.numpy())\n",
    "        rid = list(rid.numpy())\n",
    "        cid = list(cid.numpy())\n",
    "        #orig_image = tlabels.numpy()\n",
    "        #print(i,predicted.shape,orig_image.shape,len(rid),len(cid),len(tlabels))\n",
    "        \n",
    "        map_pred_img_ensemble = aggregate(map_pred_img_ensemble,predicted, rid, cid, \n",
    "                                          tids, patch_size)\n",
    "    \n",
    "    fname = 'rmse_all_'+str(batch_size)+'_'+str(len(testloader))+'.txt'\n",
    "    error_file=open(dir_out+fname,'w')\n",
    "    total_err =0\n",
    "    Ypred =[]\n",
    "    for l in range(0,len(id_test)):\n",
    "        tid = id_test[l][0]\n",
    "        targets = map_pred_img_ensemble[tid]\n",
    "        #loss = np.mean((Xtest[l] - targets)**2)\n",
    "        loss = rmse(targets, Ytest[l][0])\n",
    "        total_err+=loss\n",
    "        #print(tid,loss,Xtest[l][0].shape, targets.shape)\n",
    "        string=str(tid)+','+str(loss.item())+'\\n'\n",
    "        error_file.write(string)\n",
    "        Ypred.append(targets)\n",
    "        \n",
    "    print('total:',total_err/(len(testloader)*batch_size))\n",
    "    string='total,'+str(total_err)+'\\n'\n",
    "    error_file.write(string)\n",
    "        \n",
    "    error_file.close()\n",
    "    \n",
    "    return Xtest, Ytest, Ypred, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xtest, ytest, ypred, idtest = test_all(device,batch_size, patch_size, dir_out, dir_model,\n",
    "                                   dir_base_data, dir_super_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb863e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_dir= 'results/super-resolve/rmse_all_256_1601.txt'\n",
    "\n",
    "rmse ={}\n",
    "with open(result_dir) as f:\n",
    "    for line in f:\n",
    "        node, rmse_sc = line.split(',')\n",
    "        if node!='total':\n",
    "            node = int(node)\n",
    "            rmse_sc = float(rmse_sc)\n",
    "            rmse[node] = rmse_sc\n",
    "\n",
    "            #print(node,rmse_sc)\n",
    "        \n",
    "        #num_lines+=1\n",
    "normed_rmse = list(rmse.values())\n",
    "normed_rmse = np.array(normed_rmse)\n",
    "#tmp = (normed_rmse-np.min(normed_rmse))/(np.max(normed_rmse)-np.min(normed_rmse))\n",
    "a = np.min(normed_rmse)\n",
    "b = (np.max(normed_rmse)-np.min(normed_rmse))\n",
    "\n",
    "\n",
    "normalised_rmse = {k: (v-a)/(b-a) for k, v in rmse.items() }  \n",
    "\n",
    "print(normed_rmse.shape, len(list(normalised_rmse.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56943c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2_4x'\n",
    "with ad2.open('{}/xgc.mesh.bp'.format(indir), 'r') as f:\n",
    "    nnodes = int(f.read('n_n', ))\n",
    "    ncells = int(f.read('n_t', ))\n",
    "    rz = f.read('rz')\n",
    "    conn = f.read('nd_connect_list')\n",
    "    psi = f.read('psi')\n",
    "    nextnode = f.read('nextnode')\n",
    "    epsilon = f.read('epsilon')\n",
    "    node_vol = f.read('node_vol')\n",
    "    node_vol_nearest = f.read('node_vol_nearest')\n",
    "r = rz[:,0]\n",
    "z = rz[:,1]\n",
    "print(rz.shape)\n",
    "print (nnodes,ncells)\n",
    "#print(conn)\n",
    "print(node_vol.shape,psi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import colormaps as cmaps\n",
    "from matplotlib import colors\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "print(r.shape, z.shape,normed_rmse.shape, nnodes)\n",
    "\n",
    "plt.figure(figsize=[10,16])\n",
    "trimesh = tri.Triangulation(r, z, conn)\n",
    "plt.triplot(trimesh, alpha=0.3)\n",
    "plt.xlabel('R[m]')\n",
    "plt.ylabel('Z[m]')\n",
    "plt.title('XGC mesh')\n",
    "plt.axis('scaled')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.set_cmap(cmaps.viridis)\n",
    "norm = colors.Normalize(np.min(normed_rmse), np.max(normed_rmse))\n",
    "nc = plt.cm.seismic(norm(normed_rmse))\n",
    "print(nc.shape)\n",
    "#plt.triplot(r, z, trimesh, color=nc, marker = 'o', lw=2)\n",
    "#print(trimesh.shape)\n",
    "for i in range(0,nnodes-1):\n",
    "  #nc = plt.cm.viridis(norm(normed_rmse[i]))\n",
    "  #print(i,r[i],z[i], nc[i])\n",
    "  plt.plot(r[i], z[i], color =nc[i,:], marker = 'o', lw=2)\n",
    "  #plt.text(r[i], z[i], i)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.hot, norm=colors.Normalize(np.min(normed_rmse), np.max(normed_rmse)))\n",
    "plt.colorbar(sm)\n",
    "plt.savefig('mesh.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c1db0-5c98-4ac9-a2ed-a73581f2fd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
