{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5956f2-f071-45bb-8b1d-ab3774b43b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random \n",
    "import tqdm\n",
    "\n",
    "import adios2 as ad2\n",
    "#import pymetis\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze | grep adios2\n",
    "conda install -c conda-forge pymetis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddc7f2-66a0-47b4-af0a-057e95fccf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch-model-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af5791-9cd6-42b4-b36b-4b261bba7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install adios2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5e6fa-5b48-4e20-8d4c-b3c12bcb3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_f0(istep, expdir=None, iphi=None, inode=0, nnodes=None, average=False, \n",
    "            randomread=0.0, nchunk=16, fieldline=False):\n",
    "    \"\"\"\n",
    "    Read XGC f0 data\n",
    "    \"\"\"\n",
    "    def adios2_get_shape(f, varname):\n",
    "        nstep = int(f.available_variables()[varname]['AvailableStepsCount'])\n",
    "        shape = f.available_variables()[varname]['Shape']\n",
    "        lshape = None\n",
    "        if shape == '':\n",
    "            ## Accessing Adios1 file\n",
    "            ## Read data and figure out\n",
    "            v = f.read(varname)\n",
    "            lshape = v.shape\n",
    "        else:\n",
    "            lshape = tuple([ int(x.strip(',')) for x in shape.strip().split() ])\n",
    "        return (nstep, lshape)\n",
    "\n",
    "    fname = os.path.join(expdir, 'restart_dir/xgc.f0.%05d.bp'%istep)\n",
    "    if randomread > 0.0:\n",
    "        ## prefetch to get metadata\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0]\n",
    "            _nnodes = nsize[2] if nnodes is None else nnodes\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "        assert _nnodes%nchunk == 0\n",
    "        _lnodes = list(range(inode, inode+_nnodes, nchunk))\n",
    "        lnodes = random.sample(_lnodes, k=int(len(_lnodes)*randomread))\n",
    "        lnodes = np.sort(lnodes)\n",
    "\n",
    "        lf = list()\n",
    "        li = list()\n",
    "        for i in tqdm(lnodes):\n",
    "            li.append(np.array(range(i,i+nchunk), dtype=np.int32))\n",
    "            with ad2.open(fname, 'r') as f:\n",
    "                nphi = nsize[0] if iphi is None else 1\n",
    "                iphi = 0 if iphi is None else iphi \n",
    "                #this is considering single planes, there are 8 planes\n",
    "                start = (iphi,0,i,0)\n",
    "                count = (nphi,nmu,nchunk,nvp)\n",
    "                _f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "                lf.append(_f)\n",
    "        i_f = np.concatenate(lf, axis=2)\n",
    "        lb = np.concatenate(li)\n",
    "    elif fieldline is True:\n",
    "        import networkx as nx\n",
    "\n",
    "        fname2 = os.path.join(expdir, 'xgc.mesh.bp')\n",
    "        with ad2.open(fname2, 'r') as f:\n",
    "            _nnodes = int(f.read('n_n', ))\n",
    "            nextnode = f.read('nextnode')\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        for i in range(_nnodes):\n",
    "            G.add_node(i)\n",
    "        for i in range(_nnodes):\n",
    "            G.add_edge(i, nextnode[i])\n",
    "            G.add_edge(nextnode[i], i)\n",
    "        cc = [x for x in list(nx.connected_components(G)) if len(x) >= 16]\n",
    "\n",
    "        li = list()\n",
    "        for k, components in enumerate(cc):\n",
    "            DG = nx.DiGraph()\n",
    "            for i in components:\n",
    "                DG.add_node(i)\n",
    "            for i in components:\n",
    "                DG.add_edge(i, nextnode[i])\n",
    "            \n",
    "            cycle = list(nx.find_cycle(DG))\n",
    "            DG.remove_edge(*cycle[-1])\n",
    "            \n",
    "            path = nx.dag_longest_path(DG)\n",
    "            #print (k, len(components), path[0])\n",
    "            for i in path[:len(path)-len(path)%16]:\n",
    "                li.append(i)\n",
    "\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0] if iphi is None else 1\n",
    "            iphi = 0 if iphi is None else iphi\n",
    "            _nnodes = nsize[2]\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "            start = (iphi,0,0,0)\n",
    "            count = (nphi,nmu,_nnodes,nvp)\n",
    "            logging.info (f\"Reading: {start} {count}\")\n",
    "            i_f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "        \n",
    "        _nnodes = len(li)-inode if nnodes is None else nnodes\n",
    "        lb = np.array(li[inode:inode+_nnodes], dtype=np.int32)\n",
    "        logging.info (f\"Fieldline: {len(lb)}\")\n",
    "        logging.info (f\"{lb}\")\n",
    "        i_f = i_f[:,:,lb,:]\n",
    "    else:\n",
    "        with ad2.open(fname, 'r') as f:\n",
    "            nstep, nsize = adios2_get_shape(f, 'i_f')\n",
    "            ndim = len(nsize)\n",
    "            nphi = nsize[0] if iphi is None else 1\n",
    "            iphi = 0 if iphi is None else iphi\n",
    "            _nnodes = nsize[2]-inode if nnodes is None else nnodes\n",
    "            nmu = nsize[1]\n",
    "            nvp = nsize[3]\n",
    "            start = (iphi,0,inode,0)\n",
    "            count = (nphi,nmu,_nnodes,nvp)\n",
    "            logging.info (f\"Reading: {start} {count}\")\n",
    "            i_f = f.read('i_f', start=start, count=count).astype('float64')\n",
    "            #e_f = f.read('e_f')\n",
    "        li = list(range(inode, inode+_nnodes))\n",
    "        lb = np.array(li, dtype=np.int32)\n",
    "\n",
    "    if i_f.shape[3] == 39:\n",
    "        i_f = np.append(i_f, i_f[...,38:39], axis=3)\n",
    "        i_f = np.append(i_f, i_f[:,38:39,:,:], axis=1)\n",
    "\n",
    "    Z0 = np.moveaxis(i_f, 1, 2)\n",
    "\n",
    "    if average:\n",
    "        Z0 = np.mean(Z0, axis=0)\n",
    "        zlb = lb\n",
    "    else:\n",
    "        Z0 = Z0.reshape((-1,Z0.shape[2],Z0.shape[3]))\n",
    "        _lb = list()\n",
    "        for i in range(nphi):\n",
    "            _lb.append( i*100_000_000 + lb)\n",
    "        zlb = np.concatenate(_lb)\n",
    "    \n",
    "    #zlb = np.concatenate(li)\n",
    "    zmu = np.mean(Z0, axis=(1,2))\n",
    "    zsig = np.std(Z0, axis=(1,2))\n",
    "    zmin = np.min(Z0, axis=(1,2))\n",
    "    zmax = np.max(Z0, axis=(1,2))\n",
    "    Zif = (Z0 - zmin[:,np.newaxis,np.newaxis])/(zmax-zmin)[:,np.newaxis,np.newaxis]\n",
    "\n",
    "    return (Z0, Zif, zmu, zsig, zmin, zmax, zlb)\n",
    "\n",
    "def read_data(base_data_dir, super_data_dir, num_channels=1):\n",
    "    Z0, Zif, zmu, zsig, zmin, zmax, zlb = read_f0(420, expdir=base_data_dir, iphi=0)\n",
    "    Z0_s, Zif_s, zmu_s, zsig_s, zmin_s, zmax_s, zlb_s = read_f0(420, expdir=super_data_dir, iphi=0)\n",
    "    #print('base:',Zif.shape, zlb.shape, zmu.shape, zsig.shape)\n",
    "    #print('super:',Zif_s.shape, zlb_s.shape, zmu_s.shape, zsig_s.shape)\n",
    "    \n",
    "    lx = list()\n",
    "    ly = list()\n",
    "    for i in range(0,len(Zif)-num_channels,num_channels):\n",
    "        X = Zif[i:i+num_channels,:,:]\n",
    "        lx.append(X)\n",
    "        ly.append(zlb[i:i+num_channels])\n",
    "    \n",
    "    X_train, X_test, id_train, id_test = train_test_split(lx, ly, test_size=0.10, random_state=42)\n",
    "    \n",
    "    #Y_train = list()\n",
    "    #Y_test = list()\n",
    "    x_s = list()\n",
    "    for i in range(0,len(Zif_s)-num_channels,num_channels):\n",
    "        X = Zif_s[i:i+num_channels,:,:]\n",
    "        x_s.append(X)\n",
    "    \n",
    "    '''\n",
    "    for ids in id_train:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        Y_train.append(X)\n",
    "    \n",
    "    for ids in id_test:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        Y_test.append(X)\n",
    "    '''\n",
    "    \n",
    "    return lx,x_s, id_train, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa899c8-151e-4786-b02e-ddc815b89de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGCSuperDatasetMultiRegion:\n",
    "    def __init__(self, base_X, base_Y, ids, num_cluster, node_per_anchor, patch_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.image_X = base_X\n",
    "        self.image_Y = base_Y\n",
    "        self.id_list = ids\n",
    "        self.num_grp=num_cluster\n",
    "        self.patch_size = patch_size\n",
    "        self.grp=[]\n",
    "        self.id_len=len(node_per_anchor[0])\n",
    "        for c in range(num_cluster):\n",
    "            self.grp.append(node_per_anchor[c])\n",
    "        \n",
    "        orig_sz = base_X[0].shape[1]\n",
    "        self.image_size = int(orig_sz/patch_size)\n",
    "        self.num_patches = int((orig_sz*orig_sz)/(patch_size*patch_size))\n",
    "        self.ids =[]\n",
    "        self.sub_ids=[]\n",
    "        \n",
    "        for i in range(0,self.id_len):\n",
    "            self.ids+=self.num_patches*[i]\n",
    "            self.sub_ids+=range(0,self.num_patches)\n",
    "    \n",
    "        #print('init:',len(self.ids),self.grp[0][self.ids[0]],self.grp[1][self.ids[0]])\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.ids) \n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        idx = self.ids[i]\n",
    "        sub_idx = self.sub_ids[i]\n",
    "        \n",
    "        ridx = int(sub_idx/self.image_size)\n",
    "        cidx = int(sub_idx%self.image_size)\n",
    "        \n",
    "        rs= ridx*self.patch_size\n",
    "        re = rs+self.patch_size\n",
    "        cs = cidx*self.patch_size\n",
    "        ce = cs+self.patch_size\n",
    "        \n",
    "        base_images=[]\n",
    "        super_images=[]\n",
    "        labels=[]\n",
    "        si_list =[]\n",
    "        for j in range(self.num_grp):\n",
    "            label = self.grp[j][idx]\n",
    "            base_image = self.image_X[label]\n",
    "            base_image=base_image[0,:,:]\n",
    "        \n",
    "            super_image = self.image_Y[label]\n",
    "            super_image= super_image[0,:,:]\n",
    "            \n",
    "            X_img = base_image[rs:re,cs:ce]\n",
    "            X_img = X_img[np.newaxis,:,:]\n",
    "        \n",
    "            Y_img = super_image[rs:re,cs:ce]\n",
    "            Y_img = Y_img[np.newaxis,:,:]\n",
    "            \n",
    "            si = np.zeros(self.num_grp)\n",
    "            si[j] = 1\n",
    "            \n",
    "            base_images.append(X_img)\n",
    "            super_images.append(Y_img)\n",
    "            labels.append(label)\n",
    "            si_list.append(si)\n",
    "        \n",
    "        #print(orig_image.shape)\n",
    "        sample1 = {'X': torch.as_tensor(base_images[0].copy()).float(), \n",
    "                  'Y': torch.as_tensor(super_images[0].copy()),\n",
    "                  'S': torch.as_tensor(si_list[0].copy()),\n",
    "                  'label': labels[0],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        sample2 = {'X': torch.as_tensor(base_images[1].copy()).float(), \n",
    "                  'Y': torch.as_tensor(super_images[1].copy()),\n",
    "                  'S': torch.as_tensor(si_list[1].copy()),\n",
    "                  'label': labels[1],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        sample3 = {'X': torch.as_tensor(base_images[2].copy()).float(), \n",
    "                  'Y': torch.as_tensor(super_images[2].copy()),\n",
    "                  'S': torch.as_tensor(si_list[2].copy()),\n",
    "                  'label': labels[2],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        sample4 = {'X': torch.as_tensor(base_images[3].copy()).float(), \n",
    "                  'Y': torch.as_tensor(super_images[3].copy()),\n",
    "                  'S': torch.as_tensor(si_list[3].copy()),\n",
    "                  'label': labels[3],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        sample5 = {'X': torch.as_tensor(base_images[4].copy()).float(), \n",
    "                  'Y': torch.as_tensor(super_images[4].copy()),\n",
    "                  'S': torch.as_tensor(si_list[4].copy()),\n",
    "                  'label': labels[4],\n",
    "                  'rsid': rs, 'csid':cs}\n",
    "        \n",
    "        \n",
    "        return [sample1,sample2,sample3,sample4,sample5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184679bc",
   "metadata": {},
   "source": [
    "# Select anchor nodes over mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389abf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"/Users/oit/desktop/anika-macbook/datasets/ornl/fusion-energy-xgc/d3d_coarse_v2_colab\"\n",
    "inputdir=\"/gpfs/alpine/world-shared/csc143/jyc/summit\"\n",
    "with ad2.open('{}/d3d_coarse_small_v2/xgc.mesh.bp'.format(inputdir), 'r') as f:\n",
    "    nnodes = int(f.read('n_n', ))\n",
    "    ncells = int(f.read('n_t', ))\n",
    "    rz = f.read('rz')\n",
    "    conn = f.read('nd_connect_list')\n",
    "    psi = f.read('psi')\n",
    "    \n",
    "r = rz[:,0]\n",
    "z = rz[:,1]\n",
    "sml_nphi = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.shape,psi.shape,r.shape,z.shape,nnodes,ncells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6530201-2ce2-4a83-8afc-4dd15f3629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_cluster(nnodes,r,z,num_anchor=5):\n",
    "    pairwise_dis=np.zeros(nnodes)\n",
    "    #vec_0 = np.sqrt((r[0]**2+z[0]**2))\n",
    "    \n",
    "    for i in range(1, nnodes):\n",
    "        p = (r[i]-r[0])**2 + (z[i]-z[0])**2\n",
    "        pairwise_dis[i] = np.sqrt(p)\n",
    "    \n",
    "    #print(np.min(pairwise_dis), np.max(pairwise_dis), np.mean(pairwise_dis[1:]))\n",
    "    k = num_anchor\n",
    "    nodes_per_cluster = int(nnodes/k)\n",
    "    node_set_per_anchor={}\n",
    "    cluster_per_node={}\n",
    "    \n",
    "    for i in range(k):\n",
    "        node_set_per_anchor[i]=[]\n",
    "    \n",
    "    for i in range(nnodes):\n",
    "        if i<=nodes_per_cluster:\n",
    "            cluster_per_node[i] =0\n",
    "            node_set_per_anchor[0].append(i)\n",
    "        elif i>=nodes_per_cluster and i<=2*nodes_per_cluster:\n",
    "            cluster_per_node[i] =1\n",
    "            node_set_per_anchor[1].append(i)\n",
    "        elif i>2*nodes_per_cluster and i<= 3*nodes_per_cluster:\n",
    "            cluster_per_node[i] =2\n",
    "            node_set_per_anchor[2].append(i)\n",
    "        elif i>3*nodes_per_cluster and i<=4*nodes_per_cluster:\n",
    "            cluster_per_node[i] =3\n",
    "            node_set_per_anchor[3].append(i)\n",
    "        elif i>4*nodes_per_cluster:\n",
    "            cluster_per_node[i] =4\n",
    "            node_set_per_anchor[4].append(i)\n",
    "\n",
    "\n",
    "    return pairwise_dis, cluster_per_node, node_set_per_anchor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96897bba-3174-449d-9aa0-ac081a4d233d",
   "metadata": {},
   "source": [
    "Hyper Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90926f1-eaf4-4839-8725-34bd18bf245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, f_size = 3, z_dim = 64, out_size=16, in_size=16,s_dim=100):\n",
    "        super(HyperNetwork, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.f_size = f_size\n",
    "        self.out_size = out_size\n",
    "        self.in_size = in_size\n",
    "        self.s_dim = s_dim\n",
    "        \n",
    "        #64 X 16*3*3\n",
    "        self.w1 = Parameter(torch.fmod(torch.randn((self.z_dim, self.out_size*self.f_size*self.f_size)).cuda(),2))\n",
    "        #16*3*3\n",
    "        self.b1 = Parameter(torch.fmod(torch.randn((self.out_size*self.f_size*self.f_size)).cuda(),2))\n",
    "        \n",
    "        #64 X 16*64\n",
    "        self.w2 = Parameter(torch.fmod(torch.randn((self.z_dim, self.in_size*self.z_dim)).cuda(),2))\n",
    "        #16*64 X 1\n",
    "        self.b2 = Parameter(torch.fmod(torch.randn((self.in_size*self.z_dim)).cuda(),2))\n",
    "        \n",
    "        #100 X 16*64\n",
    "        self.w3 = Parameter(torch.fmod(torch.randn((self.s_dim, self.in_size*self.z_dim)).cuda(),2))\n",
    "        #16*64 X 1\n",
    "        self.b3 = Parameter(torch.fmod(torch.randn((self.in_size*self.z_dim)).cuda(),2))\n",
    "        \n",
    "    def forward(self, z,si): #100 \n",
    "\n",
    "        h_in = torch.matmul(z, self.w2) + self.b2    # input 64 dim , output = 16*64\n",
    "        h_in = h_in.view(self.in_size, self.z_dim)   #16 X 64\n",
    "        \n",
    "        h_spatial_in = torch.matmul(si,self.w3) + self.b3  #input 100 dim, output = 16*64 \n",
    "        h_spatial_in = h_spatial_in.view(self.in_size, self.z_dim) #16 X 64\n",
    "        \n",
    "        h_new = h_spatial_in + h_in #Add values of learnable and spatial embeddings once in same latent space\n",
    "\n",
    "        #h_final = torch.matmul(h_in, self.w1) + self.b1  # input 16 X 64, output = 16 X 16*3*3 \n",
    "        #kernel = h_final.view(self.out_size, self.in_size, self.f_size, self.f_size) # 16 X 16 X 3 X 3\n",
    "        \n",
    "        h_final = torch.matmul(h_new, self.w1) + self.b1  # input 16 X 64, output = 16 X 16*3*3 \n",
    "        kernel = h_final.view(self.out_size, self.in_size, self.f_size, self.f_size) # 16 X 16 X 3 X 3\n",
    "\n",
    "        return kernel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2c45f-0bab-42b3-8009-a6b9c66bf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet Block\n",
    "\n",
    "class IdentityLayer(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size=16, out_size=16, downsample = False):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.in_size = in_size\n",
    "        if downsample:\n",
    "            self.stride1 = 2\n",
    "            self.reslayer = nn.Conv2d(in_channels=self.in_size, out_channels=self.out_size, \n",
    "                                      stride=2, kernel_size=1)\n",
    "        else:\n",
    "            self.stride1 = 1\n",
    "            self.reslayer = IdentityLayer()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_size)\n",
    "        self.bn2 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "    def forward(self, x, conv1_w, conv2_w):\n",
    "\n",
    "        residual = self.reslayer(x)\n",
    "\n",
    "        out = F.relu(self.bn1(F.conv2d(x, conv1_w, stride=self.stride1, padding=1)), inplace=True)\n",
    "        out = self.bn2(F.conv2d(out, conv2_w, padding=1))\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50809a-9946-493a-a5e5-e496578a6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, z_num, z_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        self.z_list = nn.ParameterList()\n",
    "        self.z_num = z_num\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        h,k = self.z_num\n",
    "\n",
    "        for i in range(h):\n",
    "            for j in range(k):\n",
    "                self.z_list.append(Parameter(torch.fmod(torch.randn(self.z_dim).cuda(), 2)))\n",
    "\n",
    "    def forward(self, hyper_net,si): #si is the spatial encoding vector.\n",
    "        ww = []\n",
    "        h, k = self.z_num\n",
    "        for i in range(h):\n",
    "            w = []\n",
    "            for j in range(k):\n",
    "                w.append(hyper_net(self.z_list[i*k + j],si))\n",
    "            ww.append(torch.cat(w, dim=1))\n",
    "        return torch.cat(ww, dim=0)\n",
    "\n",
    "\n",
    "class PrimaryNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=64, patch_size=5, s_dim=99):\n",
    "        super(PrimaryNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.patch_size= patch_size\n",
    "        self.z_dim = z_dim\n",
    "        self.s_dim = s_dim\n",
    "        self.hope = HyperNetwork(z_dim=self.z_dim, s_dim = self.s_dim)\n",
    "\n",
    "        self.zs_size = [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1],\n",
    "                        [2, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2],\n",
    "                        [4, 2], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4], [4, 4]]\n",
    "\n",
    "        self.filter_size = [[16,16], [16,16], [16,16], [16,16], [16,16], [16,16], [16,32], [32,32], [32,32], [32,32],\n",
    "                            [32,32], [32,32], [32,64], [64,64], [64,64], [64,64], [64,64], [64,64]]\n",
    "\n",
    "        self.res_net = nn.ModuleList()\n",
    "\n",
    "        for i in range(18):\n",
    "            down_sample = False\n",
    "            if i > 5 and i % 6 == 0:\n",
    "                down_sample = True\n",
    "            self.res_net.append(ResNetBlock(self.filter_size[i][0], self.filter_size[i][1], downsample=down_sample))\n",
    "\n",
    "        self.zs = nn.ModuleList()\n",
    "\n",
    "        for i in range(36):\n",
    "            self.zs.append(Embedding(self.zs_size[i], self.z_dim))\n",
    "\n",
    "        self.global_avg = nn.AvgPool2d(8)\n",
    "        self.final = nn.Linear(256,self.patch_size*self.patch_size)\n",
    "\n",
    "    def forward(self, x,si): # where si is the (num_nodes X 1) spatial-encoding vector\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #print('conv1:',x.shape)\n",
    "        for i in range(18):\n",
    "            # if i != 15 and i != 17:\n",
    "            w1 = self.zs[2*i](self.hope,si) #Note the SAME si is passed for all sub_parts x of a single image X_i\n",
    "            w2 = self.zs[2*i+1](self.hope,si)\n",
    "            x = self.res_net[i](x, w1, w2)\n",
    "            #print('resnet:',i,x.shape)\n",
    "        \n",
    "        #print('final resnet:',x.shape)\n",
    "        \n",
    "        #x = self.global_avg(x)\n",
    "        #print('avg pool:',x.shape)\n",
    "        x = self.final(x.view(-1,256))\n",
    "        x = x.view(-1,1,self.patch_size,self.patch_size)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6b81d-93f1-4a6e-af23-3cffaa62eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_model_summary import summary\n",
    "net = PrimaryNetwork(patch_size=8, s_dim=5)\n",
    "total=0\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if name.find('res_net'):\n",
    "            #print(name, param.numel())\n",
    "            total+=param.numel()\n",
    "        else:\n",
    "            continue      \n",
    "\n",
    "print('total:',total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bbfd5-2eb2-4bf6-a4cf-c1ed50943990",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494f0a2-444d-4335-aeda-fbaaaab35825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfc3ed-9aac-49e9-82e6-f6df6e1bb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(patch_size, batch_size, num_anchor):\n",
    "    \n",
    "    X, Y, id_train, id_test = read_data(dir_base_data, dir_super_data)\n",
    "    \n",
    "    si, cluster_per_node, node_per_anchor = spatial_cluster(nnodes, r, z, num_anchor=num_anchor)\n",
    "    max_id_train= 0\n",
    "    max_id_test = 0\n",
    "    \n",
    "    #print(len(X_train), len(X_test), len(Y_train), len(Y_test))\n",
    "    train_node_per_anchor={}\n",
    "    test_node_per_anchor={}\n",
    "    for idx in range(num_anchor):\n",
    "        list_ids = node_per_anchor[idx]\n",
    "        list_train =[]\n",
    "        list_test =[]\n",
    "        for ids in list_ids:\n",
    "            if ids in id_train:\n",
    "                list_train.append(ids)\n",
    "            elif ids in id_test:\n",
    "                list_test.append(ids)\n",
    "        \n",
    "        train_node_per_anchor[idx] = list_train\n",
    "        test_node_per_anchor[idx] = list_test\n",
    "        \n",
    "        if len(list_train)>max_id_train:\n",
    "            max_id_train = len(list_train)\n",
    "        \n",
    "        if len(list_test)>max_id_test:\n",
    "            max_id_test = len(list_test)\n",
    "    \n",
    "    #print('max #nodes:',max_id_train, max_id_test)\n",
    "    for idx in range(num_anchor):\n",
    "        list_ids_tr =  train_node_per_anchor[idx]\n",
    "        list_ids_te = test_node_per_anchor[idx]\n",
    "        \n",
    "        if len(list_ids_tr)<max_id_train:\n",
    "            num_xtra_samples = max_id_train-len(list_ids_tr)\n",
    "            samples = random.sample(list_ids_tr,num_xtra_samples)\n",
    "            list_ids_tr+=samples\n",
    "            train_node_per_anchor[idx] = list_ids_tr\n",
    "        \n",
    "        if len(list_ids_te)<max_id_test:\n",
    "            num_xtra_samples = max_id_test-len(list_ids_te)\n",
    "            samples = random.sample(list_ids_te,num_xtra_samples)\n",
    "            list_ids_te+=samples\n",
    "            test_node_per_anchor[idx] = list_ids_te\n",
    "        \n",
    "        #print('idx:',idx, len(train_node_per_anchor[idx]),len(test_node_per_anchor[idx]))\n",
    "        \n",
    "    trainset = XGCSuperDatasetMultiRegion(X, Y, id_train, num_anchor, train_node_per_anchor, patch_size)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "    testset = XGCSuperDatasetMultiRegion(X, Y, id_test, num_anchor, test_node_per_anchor, patch_size)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print('data loader:',idx, len(trainloader),len(testloader))\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe9d20-48be-43d8-a3b3-f68c24256203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(device, net, testloader, criterion, num_cluster):\n",
    "    correct = 0.\n",
    "    total =0 \n",
    "    num_test=0\n",
    "    #net.eval()\n",
    "    for tdata in testloader:\n",
    "        for cl in range(num_cluster):\n",
    "            timages, tlabels, S = tdata[cl]['X'], tdata[cl]['Y'], tdata[cl]['S']\n",
    "            #tlables = Variable(tlabels1.cuda())\n",
    "            timages = Variable(timages.cuda())\n",
    "            si = Variable(S[0].cuda())\n",
    "            with torch.no_grad():   \n",
    "                toutputs = net(timages.double(),si.double())\n",
    "                predicted = toutputs.cpu().data\n",
    "                error= criterion(predicted,tlabels)\n",
    "                correct+=error.item()\n",
    "        \n",
    "        total+=num_cluster\n",
    "        \n",
    "    return correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b2d1-94c3-40a1-b6b7-4716cf5851ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 50 #256\n",
    "save_freq = 20\n",
    "patch_size = 8 \n",
    "print_freq = 20\n",
    "s_dim =5\n",
    "dir_out = 'checkpoint/hypernet-concentric-microbatch/'\n",
    "dir_resume = 'checkpoint/hypernet-concentric-microbatch/hypernet_plasma_35.pth'\n",
    "resume_epoch = 35\n",
    "dir_base_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2' \n",
    "dir_super_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2_4x' \n",
    "resume = True\n",
    "\n",
    "\n",
    "if not os.path.exists(dir_out):\n",
    "        os.makedirs(dir_out)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224b65f",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea9deb-9536-44fd-a08d-8dd4a1337698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_microbatch(device, s_dim):\n",
    "    trainloaders, testloaders = set_data(patch_size, batch_size, s_dim)\n",
    "    \n",
    "    net = PrimaryNetwork(patch_size=patch_size, s_dim = s_dim)\n",
    "    best_accuracy = 10000.\n",
    "    total_iter = 0\n",
    "    epoch = 0\n",
    "    loss_file=open(dir_out+'microbatch_loss.txt','a')\n",
    "    if resume:\n",
    "        ckpt = torch.load(dir_resume)\n",
    "        net.load_state_dict(ckpt['net'])\n",
    "        best_accuracy = ckpt['acc']\n",
    "        total_iter= resume_epoch\n",
    "        epoch=resume_epoch\n",
    "    else:\n",
    "        loss_file.write('epoch,loss1,loss2,loss3,loss4,loss5,loss,val_loss\\n')\n",
    "    net = net.double()\n",
    "    net.cuda()\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 0.0005\n",
    "    milestones = [100, 150, 200, 500, 1000]\n",
    "    max_iter = epochs\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    num_batch = len(trainloaders)\n",
    "    #print_freq = args.print_freq\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    while total_iter < max_iter:\n",
    "\n",
    "        running_loss = 0.0\n",
    "        epoch_loss=0\n",
    "        grp_loss=np.zeros(s_dim)\n",
    "        epoch=0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, sample in enumerate(trainloaders,0):\n",
    "            optimizer.zero_grad()\n",
    "            for cl in range(s_dim-1):\n",
    "                #Sample 1\n",
    "                inputs = sample[cl]['X']\n",
    "                labels = sample[cl]['Y']\n",
    "                si = sample[cl]['S']\n",
    "                \n",
    "                inputs= Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                si = Variable(si[0].cuda())\n",
    "                \n",
    "                outputs = net(inputs.double(), si.double())\n",
    "                loss = criterion(outputs, labels) #+ physics_loss()\n",
    "                loss.backward(retain_graph=True)\n",
    "                \n",
    "                grp_loss[cl]+=loss.item()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                epoch_loss+=loss.item()\n",
    "            \n",
    "            #last Sample of the microbatch\n",
    "            cl = s_dim-1\n",
    "            inputs_l = sample[cl]['X']\n",
    "            labels_l = sample[cl]['Y']\n",
    "            si_l = sample[cl]['S']\n",
    "            \n",
    "            inputs_l= Variable(inputs_l.cuda())\n",
    "            labels_l = Variable(labels_l.cuda())\n",
    "            si_l = Variable(si_l[0].cuda())\n",
    "            \n",
    "            outputs_l = net(inputs_l.double(), si_l.double())\n",
    "            \n",
    "            loss = criterion(outputs_l, labels_l) #+ physics_loss()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            #lr_scheduler.step()\n",
    "            \n",
    "            grp_loss[cl]+=loss.item()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss+=loss.item()\n",
    "            if i % print_freq == (print_freq-1):\n",
    "                print(\"[Epoch %d, loader %d] Loss: %.6f\" % (total_iter + 1, \n",
    "                                                                i + 1, \n",
    "                                                                running_loss/(s_dim*print_freq)))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        total_iter += 1\n",
    "        \n",
    "        correct, total= validate(device, net, testloaders, criterion, s_dim) #Update this function appropriately.\n",
    "        \n",
    "        epoch_loss/=(num_batch*s_dim)\n",
    "        grp_loss/=num_batch\n",
    "        val_loss = correct/total\n",
    "        string2=''\n",
    "        for cl in range(s_dim):\n",
    "            string2+= str(grp_loss[cl])+','\n",
    "        \n",
    "        string1=str(total_iter)+','+string2+str(epoch_loss)+','+str(val_loss)+'\\n'\n",
    "        loss_file.write(string1)\n",
    "        print('After epoch %d, validation loss: %.6f' % (total_iter, val_loss))\n",
    "\n",
    "        if val_loss < best_accuracy:\n",
    "            print('Saving model...')\n",
    "            state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': val_loss\n",
    "            }\n",
    "            torch.save(state, dir_out+'hypernet_plasma_'+str(total_iter)+'.pth')\n",
    "            best_accuracy = val_loss\n",
    "        \n",
    "    print('Finished Training')\n",
    "    state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': val_loss\n",
    "            }\n",
    "    torch.save(state, dir_out+'last.pth')\n",
    "    loss_file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c8315-8308-4061-ba04-8975ec03de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_microbatch(device, s_dim)\n",
    "end = time.time()\n",
    "\n",
    "total = end-start\n",
    "print('Finished Training in '+str(total)+' sec.')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8983e3f-cb12-4ff9-82f8-ce05ace6dce7",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31956e-a86e-427e-8bb8-d7f0ea6c9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, dir_base_data, dir_super_data, patch_size, num_anchor, readall=False):\n",
    "    if readall:\n",
    "        X, Y, id_test = read_all(dir_base_data, dir_super_data)\n",
    "    else:\n",
    "        X, Y, id_train, id_test = read_data(dir_base_data, dir_super_data)\n",
    "    \n",
    "    si, cluster_per_node, node_per_anchor = spatial_cluster(nnodes, r, z, num_anchor=num_anchor)\n",
    "    \n",
    "    max_id_test = 0\n",
    "    \n",
    "    test_node_per_anchor={}\n",
    "    for idx in range(num_anchor):\n",
    "        list_ids = node_per_anchor[idx]\n",
    "        list_test =[]\n",
    "        for ids in list_ids:\n",
    "            if ids in id_test:\n",
    "                list_test.append(ids)\n",
    "        test_node_per_anchor[idx] = list_test\n",
    "        \n",
    "        if len(list_test)>max_id_test:\n",
    "            max_id_test = len(list_test)\n",
    "    \n",
    "    #print('max #nodes:',max_id_train, max_id_test)\n",
    "    for idx in range(num_anchor):\n",
    "        list_ids_te = test_node_per_anchor[idx]\n",
    "        \n",
    "        if len(list_ids_te)<max_id_test:\n",
    "            num_xtra_samples = max_id_test-len(list_ids_te)\n",
    "            samples = random.sample(list_ids_te,num_xtra_samples)\n",
    "            list_ids_te+=samples\n",
    "            test_node_per_anchor[idx] = list_ids_te\n",
    "        \n",
    "    \n",
    "    testset = XGCSuperDatasetMultiRegion(X, Y, list_test, num_anchor, test_node_per_anchor, patch_size)\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "        \n",
    "        \n",
    "    return testloader, X, Y, id_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300562b-baf2-4d53-a2ce-d50c0f537a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device, dir_model, s_dim):\n",
    "    net = PrimaryNetwork(patch_size=patch_size, s_dim=s_dim)\n",
    "    ckpt = torch.load(dir_model, map_location=device)\n",
    "    state_dict = ckpt['net']\n",
    "    \n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for k, v in state_dict.items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "        state_dict = new_state_dict\n",
    "    \n",
    "    net.to(device=device)\n",
    "    net.load_state_dict(state_dict)\n",
    "    \n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3701061-165b-4da7-9b29-8573e6f7fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(map_pred_img,predictions, rid, cid, labels, patch_size):\n",
    "    \n",
    "    for l in range(0,len(labels)):\n",
    "        #print(labels[l])\n",
    "        map_pred_img[labels[l]][rid[l]:rid[l]+patch_size,cid[l]:cid[l]+patch_size] = predictions[l,:,:]\n",
    "        \n",
    "    return map_pred_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78504566-78ca-4dba-a4f2-33e379807561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d702c-9a34-4155-98f4-3d9f7795ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device, batch_size, patch_size, dir_out, dir_model, dir_base_data, dir_super_data, num_anchor):\n",
    "    model = load_model(device, dir_model, num_anchor)\n",
    "    model = model.double()\n",
    "    testloaders, Xtest, Ytest, id_test = load_data(batch_size, \n",
    "                                    dir_base_data, dir_super_data, patch_size, num_anchor)\n",
    "    model.eval()\n",
    "    map_pred_img_ensemble={}\n",
    "    \n",
    "    for tid in id_test:\n",
    "        #print('test labels:',tid[0])\n",
    "        map_pred_img_ensemble[tid[0]]= np.zeros((40,40))\n",
    "        \n",
    "    for i, data in enumerate(testloaders,0):\n",
    "        for cl in range(num_anchor):\n",
    "            timages, tlabels, S = data[cl]['X'], data[cl]['Y'], data[cl]['S']\n",
    "            nid, rid, cid = data[cl]['label'],data[cl]['rsid'], data[cl]['csid']\n",
    "            #tlables = Variable(tlabels1.cuda())\n",
    "            timages = Variable(timages.cuda())\n",
    "            si = Variable(S[0].cuda())\n",
    "            with torch.no_grad():   \n",
    "                toutputs = model(timages.double(),si.double())\n",
    "                predicted = toutputs.cpu().data\n",
    "                \n",
    "            predicted = predicted.squeeze()\n",
    "            predicted = predicted.numpy()\n",
    "            tids = list(nid.numpy())\n",
    "            rid = list(rid.numpy())\n",
    "            cid = list(cid.numpy())\n",
    "            #print(i,predicted.shape,orig_image.shape,len(rid),len(cid),len(tlabels))\n",
    "        \n",
    "            map_pred_img_ensemble = aggregate(map_pred_img_ensemble,predicted, rid, cid, \n",
    "                                          tids, patch_size)\n",
    "    \n",
    "    fname = 'rmse_xgc_test_'+str(batch_size)+'_'+str(len(testloaders))+'.txt'\n",
    "    error_file=open(dir_out+fname,'w')\n",
    "    total_err =0\n",
    "    Ypred =[]\n",
    "    for l in range(0,len(id_test)):\n",
    "        tid = id_test[l][0]\n",
    "        targets = map_pred_img_ensemble[tid]\n",
    "        loss = rmse(targets, Ytest[l][0])\n",
    "        total_err+=loss\n",
    "        #print(tid,loss,Xtest[l][0].shape, targets.shape)\n",
    "        string=str(tid)+','+str(loss.item())+'\\n'\n",
    "        error_file.write(string)\n",
    "        Ypred.append(targets)\n",
    "        \n",
    "    print('total:',total_err/len(id_test))\n",
    "    string='total,'+str(total_err)+'\\n'\n",
    "    error_file.write(string)\n",
    "        \n",
    "    error_file.close()\n",
    "    \n",
    "    return Xtest, Ytest, Ypred, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507f23b-9499-4e12-ae43-7d97fd8cd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "patch_size = 8\n",
    "s_dim = 5\n",
    "dir_out = 'results/hypernet-concentric-microbatch/'\n",
    "dir_model = 'checkpoint/hypernet-concentric-microbatch/hypernet_plasma_50.pth'\n",
    "dir_base_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2'\n",
    "dir_super_data = '/gpfs/alpine/world-shared/csc143/jyc/summit/d3d_coarse_small_v2_4x'\n",
    "if not os.path.exists(dir_out):\n",
    "        os.makedirs(dir_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85ed70-aaf4-469b-9ee5-e264456f7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xtest, ytest, ypred, idtest = test(device,batch_size, patch_size, dir_out, dir_model,\n",
    "                                   dir_base_data, dir_super_data, s_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51905033-4884-43e8-9e0f-a1eeb98f006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,len(idtest)):\n",
    "    np.save(dir_out+'f_pred_'+str(idtest[l][0]),ypred[l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d2f5e-0f4e-411c-be9b-5f8a5951aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ny, nx = ytest[0].shape\n",
    "ix = np.linspace(0, nx-1, nx)\n",
    "iy = np.linspace(0, ny-1, ny)\n",
    "Mx, My = np.meshgrid(ix, iy)\n",
    "\n",
    "for l in range(0,len(ytest)):\n",
    "    #plt.figure(figsize=(4, 9))\n",
    "    print('idx:',l)\n",
    "    f = plt.figure(figsize=(12, 8))\n",
    "    f.add_subplot(1,3, 1)\n",
    "    plt.imshow(xtest[l][0], origin='lower')\n",
    "    #plt.colorbar()\n",
    "    plt.contour(Mx, My, ytest[l][0], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('input %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    f.add_subplot(1,3, 2)\n",
    "    plt.imshow(ytest[l][0], origin='lower')\n",
    "    #plt.colorbar()\n",
    "    plt.contour(Mx, My, ytest[l][0], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('original %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    f.add_subplot(1,3, 3)\n",
    "    plt.imshow(ypred[l], origin='lower')\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.contour(Mx, My, ypred[l], levels=5, origin='image', colors='white', alpha=0.5)\n",
    "    #RMSE = rmse(ypred[l], ytest[l][0])\n",
    "    #plt.text(.02,.95,'RMSE: {:.04f}'.format(RMSE), fontsize=14, c='white')\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    plt.title('predicted %d'%(idtest[l][0]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if l>100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840477ed",
   "metadata": {},
   "source": [
    "# Plot Error across Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all(base_data_dir, super_data_dir, num_channels=1):\n",
    "    Z0, Zif, zmu, zsig, zmin, zmax, zlb = read_f0(420, expdir=base_data_dir, iphi=0)\n",
    "    Z0_s, Zif_s, zmu_s, zsig_s, zmin_s, zmax_s, zlb_s = read_f0(420, expdir=super_data_dir, iphi=0)\n",
    "    #print('base:',Zif.shape, zlb.shape, zmu.shape, zsig.shape)\n",
    "    #print('super:',Zif_s.shape, zlb_s.shape, zmu_s.shape, zsig_s.shape)\n",
    "    \n",
    "    lx = list()\n",
    "    ly = list()\n",
    "    lid = list()\n",
    "    for i in range(0,len(Zif),num_channels):\n",
    "        X = Zif[i:i+num_channels,:,:]\n",
    "        lx.append(X)\n",
    "        lid.append(zlb[i:i+num_channels])\n",
    "    \n",
    "    #print('lid:',lid[:10])\n",
    "    for ids in lid:\n",
    "        X= Zif_s[ids[0]:ids[0]+num_channels,:,:]\n",
    "        ly.append(X)\n",
    "    \n",
    "    \n",
    "    return lx, ly, lid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(device, batch_size, patch_size, dir_out, dir_model, dir_base_data, dir_super_data, s_dim):\n",
    "    model = load_model(device, dir_model, s_dim)\n",
    "    model = model.double()\n",
    "    testloaders, Xtest, Ytest, id_test= load_data(batch_size, dir_base_data, \n",
    "                                                dir_super_data, patch_size, s_dim, \n",
    "                                                  readall=True)\n",
    "    model.eval()\n",
    "    map_pred_img_ensemble={}\n",
    "    \n",
    "    for tid in id_test:\n",
    "        #print('test labels:',tid[0])\n",
    "        map_pred_img_ensemble[tid[0]]= np.zeros((40,40))\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(testloaders,0):\n",
    "        for cl in range(s_dim):\n",
    "            timages, tlabels, S = data[cl]['X'], data[cl]['Y'], data[cl]['S']\n",
    "            nid, rid, cid = data[cl]['label'],data[cl]['rsid'], data[cl]['csid']\n",
    "            #timages = timages.to(device=device, dtype=torch.float32)\n",
    "            timages= Variable(timages.cuda())\n",
    "            si = Variable(S[0].cuda())\n",
    "            with torch.no_grad():\n",
    "                toutputs = model(timages.double(),si.double())\n",
    "                predicted = toutputs.cpu().data\n",
    "        \n",
    "            predicted = predicted.squeeze()\n",
    "            predicted = predicted.numpy()\n",
    "            tids = list(nid.numpy())\n",
    "            rid = list(rid.numpy())\n",
    "            cid = list(cid.numpy())\n",
    "            \n",
    "            map_pred_img_ensemble = aggregate(map_pred_img_ensemble,predicted, rid, cid, \n",
    "                                          tids, patch_size)\n",
    "    \n",
    "    fname = 'rmse_all_'+str(batch_size)+'.txt'\n",
    "    error_file=open(dir_out+fname,'w')\n",
    "    total_err =0\n",
    "    Ypred =[]\n",
    "    for l in range(0,len(id_test)):\n",
    "        tid = id_test[l][0]\n",
    "        targets = map_pred_img_ensemble[tid]\n",
    "        #loss = np.mean((Xtest[l] - targets)**2)\n",
    "        loss = rmse(targets, Ytest[l][0])\n",
    "        total_err+=loss\n",
    "        #print(tid,loss,Xtest[l][0].shape, targets.shape)\n",
    "        string=str(tid)+','+str(loss.item())+'\\n'\n",
    "        error_file.write(string)\n",
    "        Ypred.append(targets)\n",
    "        \n",
    "    print('total:',total_err/len(id_test))\n",
    "    string='total,'+str(total_err)+'\\n'\n",
    "    error_file.write(string)\n",
    "        \n",
    "    error_file.close()\n",
    "    \n",
    "    return Xtest, Ytest, Ypred, id_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xtest, ytest, ypred, idtest = test_all(device,batch_size, patch_size, dir_out, dir_model,\n",
    "                                   dir_base_data, dir_super_data,s_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53861ad4-7946-45dc-bb1a-38c46214b970",
   "metadata": {},
   "source": [
    "Plot all rmse error for mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb863e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result_dir= 'results/hypernet-concentric-microbatch/rmse_all_50.txt'\n",
    "rmse={}\n",
    "#rmse_test={}\n",
    "#rmse_train={}\n",
    "with open(result_dir) as f:\n",
    "    for line in f:\n",
    "        node, rmse_sc = line.split(',')\n",
    "        if node!='total':\n",
    "            node = int(node)\n",
    "            rmse_sc = float(rmse_sc)\n",
    "            rmse[node] = rmse_sc\n",
    "        \n",
    "        #num_lines+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a8242-d31b-415e-9e98-2c3eaf157918",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_rmse = list(rmse.values())\n",
    "normed_rmse = np.array(normed_rmse)\n",
    "#tmp = (normed_rmse-np.min(normed_rmse))/(np.max(normed_rmse)-np.min(normed_rmse))\n",
    "\n",
    "print(normed_rmse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e880a8-a64b-4bca-8257-4ebd94cbe493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import colormaps as cmaps\n",
    "from matplotlib import colors\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "print(r.shape, z.shape,normed_rmse.shape, nnodes)\n",
    "\n",
    "plt.figure(figsize=[10,16])\n",
    "trimesh = tri.Triangulation(r, z, conn)\n",
    "plt.triplot(trimesh, alpha=0.3)\n",
    "plt.xlabel('R[m]')\n",
    "plt.ylabel('Z[m]')\n",
    "plt.title('XGC mesh')\n",
    "plt.axis('scaled')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.set_cmap(cmaps.viridis)\n",
    "#norm = colors.Normalize(np.min(normed_rmse), np.max(normed_rmse))\n",
    "norm = colors.Normalize(0, 0.23)\n",
    "nc = plt.cm.hot(norm(normed_rmse))\n",
    "for i in range(0,len(normed_rmse)):\n",
    "  #nc = plt.cm.viridis(norm(normed_rmse[i]))\n",
    "  #print(i,r[i],z[i], nc[i])\n",
    "  plt.plot(r[i], z[i], color =nc[i,:], marker = 'o', lw=2)\n",
    "  #plt.text(r[i], z[i], i)\n",
    "\n",
    "#sm = plt.cm.ScalarMappable(cmap=plt.cm.hot, norm=colors.Normalize(np.min(normed_rmse), np.max(normed_rmse)))\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.hot, norm=colors.Normalize(0, 0.23))\n",
    "plt.colorbar(sm)\n",
    "plt.savefig('results/hypernet-concentric-microbatch/mesh_error_all_lr_.0001.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
